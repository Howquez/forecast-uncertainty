---
title: "Data Wrangling"
description: |
  Retrieve and process the survey's data.
author:
  - name: Hauke Roggenkamp 
    url: https://github.com/Howquez
    affiliation: CLICCS
    affiliation_url: https://www.cliccs.uni-hamburg.de/
date: "`r Sys.Date()`"
bibliography: biblio.bib
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
    toc_float: false
    code_folding: true
---

```{r setup}
knitr::opts_chunk$set(echo = FALSE)

library(data.table)
library(kableExtra)
library(downloadthis)
library(stringr)
library(magrittr)
# library(tidyverse)
library(glue)

```


# Load & subset data

```{r readData}
# read data
DT <- read.csv(file="../data/simulation/all_apps_wide.csv",
               stringsAsFactors = FALSE) %>% data.table()

```


This document reads simulated data generated with 200 rather simple oTree [@oTree] bots that looks as follows:

```{r showData1}
DT %>% 
  head(n = 10) %>%
  kbl() %>%
  scroll_box(width="120%") %>%
  kable_paper("hover", 
              full_width = TRUE,
              fixed_thead = TRUE)
```

Because most of the variables are secondary, I subset the data we are most interested in, that is, the variables needed to identify subjects (IDs) as well as the variables needed to calculate @Baillon2018as' indices. To conduct analyses with covariates and treatment information, one can use the IDs and merge the data.

```{r subsetData}
# select relevant columns for main- and control variables separately
mainRegex <- "^participant\\.code$|matching_probability$|event_decision$|Comprehension$"
mainVariables <- str_subset(string = names(DT),
                            pattern = mainRegex)
mt <- DT[ ,# Outro.1.player.Comprehension != "no", 
         ..mainVariables] #"mt" for Main Table (in contrast to "Control Table" oder "Data Table")

```


# Rename data

To make the variables a little more readable, I'll remove the ```.player``` substring.^[Eventually, we should rename these variables to make them shorter. Names such as ```MP[round]``` and ```event[round]``` would be great.]

```{r renameData}
oldNames <- names(mt)
newNames <- str_replace_all(string=oldNames,
                            pattern="\\.player",
                            replacement="")
setnames(x=mt,
         old=oldNames,
         new=newNames)
```

# Prepare indices

This step is not necessary and needs to be adjusted as soon as we become interested in the events itself. But for the time being, I replace the event values to ```composite``` or ```single```. This is fairly simple, because the longer event strings indicate that the subject had to bet on composite events. As a consequence, replace the values is a matter of counting characters.

```{r events}

for(round in 1:12){
  
  col = glue("Uncertainty.{round}.event_decision")
  
  set(x = mt,
      i = which(mt[[col]] %>% as.character() %>% nchar() > 2),
      j = col,
      value = "composite")
  
  set(x = mt,
      i = which(mt[[col]] %>% as.character() %>% nchar() == 2),
      j = col,
      value = "single")
}
```


# Calculate indices

This process is a little messy. To calculate the indices, we need to differentiate between composite and single events and calculate compound-event probabilities (CEPs) as well as single-event probabilities (SEPs) and their means for each observation. Having done so, one can calculate Baillon et al's _ambiguity-generated insensitivity (a-insensitivity) index_ (called AGII) as well as the _ambiguity aversion index_ (called AAI).

The subjects played the Baillon-tasks twice in the same order of events. Due to laziness, the calculation of the two sets of indices (one pre- and one post-treatment) lacks elegance and is done in two code chunks.^[Eventually, we should write either a function or a nested loop.] The pre-treatment indices are calculated as follows:

```{r calcIndices1}

#..calculate Baillons Indices
for(row in 1:NROW(mt)){
  
  #..first get a vector of event types
  vector = c()
  for(round in 1:6){
    col = glue("Uncertainty.{round}.event_decision")
    vector = append(vector, mt[row, get(col)])
  }
  
  # consider composite events first and get the round numbers where composite events were shown
  cEvents = str_which(string = vector,
                       pattern = "composite")
  # now loop over these rounds to add the respective matching_probabilities
  CEPs = NULL # Compound-Event Probabilities
  for(compositeRound in cEvents){
    col <- glue("Uncertainty.{compositeRound}.matching_probability")
    increment <- mt[row, get(col)]
    CEPs <- append(CEPs, increment)
  }
  # average
  ACEP = mean(CEPs, na.rm=TRUE)/100
  
  # do the same for single events
  sEvents <- str_which(string = vector,
                       pattern = "single")
  SEPs = NULL
  for(singleRound in sEvents){
    col <- glue("Uncertainty.{singleRound}.matching_probability")
    increment <- mt[row, get(col)]
    SEPs <- append(SEPs, increment)
  }
  ASEP = mean(SEPs, na.rm=TRUE)/100
  
  # calculate Ambiguity Aversion Index (AAI)
  AAI = 1 - ACEP - ASEP
  
  # calculate  ambiguity-generated insensitivity (a-insensitivity) index (AGII)
  AGII = 3 * (1/3 - (ACEP - ASEP))
  
  # write indices
  mt[row,
     pre_AAI := AAI]
  mt[row,
     pre_AGII := AGII]
}
```


The post-treatment indices' calculation follows the same rules but adds a ```+6``` to the event vectors. This is ugly but feasible because the sequence of events in the first 6 rounds is exactly the same as in rounds 7-12.

```{r calcIndices2}

#..calculate Baillons Indices
for(row in 1:NROW(mt)){
  
  #..first get a vector of event types
  vector = c()
  for(round in 1:6){
    col = glue("Uncertainty.{round}.event_decision")
    vector = append(vector, mt[row, get(col)])
  }
  
  # consider composite events first and get the round numbers where composite events were shown
  cEvents = str_which(string = vector,
                       pattern = "composite") + 6
  # now loop over these rounds to add the respective matching_probabilities
  CEPs = NULL # Compound-Event Probabilities
  for(compositeRound in cEvents){
    col <- glue("Uncertainty.{compositeRound}.matching_probability")
    increment <- mt[row, get(col)]
    CEPs <- append(CEPs, increment)
  }
  # average
  ACEP = mean(CEPs, na.rm=TRUE)/100
  
  # do the same for single events
  sEvents <- str_which(string = vector,
                       pattern = "single") + 6
  SEPs = NULL
  for(singleRound in sEvents){
    col <- glue("Uncertainty.{singleRound}.matching_probability")
    increment <- mt[row, get(col)]
    SEPs <- append(SEPs, increment)
  }
  ASEP = mean(SEPs, na.rm=TRUE)/100
  
  # calculate Ambiguity Aversion Index (AAI)
  AAI = 1 - ACEP - ASEP
  
  # calculate  ambiguity-generated insensitivity (a-insensitivity) index (AGII)
  AGII = 3 * (1/3 - (ACEP - ASEP))
  
  # write indices
  mt[row,
     post_AAI := AAI]
  mt[row,
     post_AGII := AGII]
}
```

Having done that, the data looks as follows.

```{r showData2}
mt %>% 
  head(n = 10) %>%
  kbl() %>%
  scroll_box(width="120%") %>%
  kable_paper("hover", 
              full_width = TRUE,
              fixed_thead = TRUE)
```

Before one can merge the data with the covariates, I transform it such that we have two rows per subject where the first row reports Baillon's indices before treatment and the second row corresponds to the post-treatment indices.

```{r}
pre <- mt[,
          .(participant.code,
           AAI = pre_AAI,
           AGII = pre_AGII,
           status = "pre")]
post <- mt[,
           .(participant.code,
           AAI = post_AAI,
           AGII = post_AGII,
           status = "post")]

MT <- rbindlist(list(pre, post))[order(participant.code)]
MT
```

# Merge data

Having done that, I merge the resulting table with the raw data. Alternatively, one could select some covariates using regular expressions once more.

```{r selectCovariates}
controlRegex <- "^participant\\.code$|time_started$|visited$|participant\\.payoff$|^Baillon.1.player.window.*|^Baillon.1.player.browser$|_index_in_pages|player\\.location$|player\\.treatment$|review_|Accuracy$|Credibility$|Comprehension$|Age$|Gender$|Education$|Income$|Usage$"
controlVariables <- str_subset(string = names(DT),
                               pattern = controlRegex)
ct <- DT[, ..controlVariables]
ct
```


Afterwards, one can rename the variables a little. I repeat the procedure applied above and remove the ```player.``` substring.

```{r renameCovariates}
oldNames <- names(ct)
newNames <- str_replace_all(string=oldNames,
                            pattern="\\.player",
                            replacement="")
setnames(x=ct,
         old=oldNames,
         new=newNames)
```

```{r mergeData}
# merge with raw data instead of ct
data <- merge(MT, DT,
              by = "participant.code")
data
```

